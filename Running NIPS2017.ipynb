{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from tempfile import mkdtemp\n",
    "import sys\n",
    "import subprocess\n",
    "import threading\n",
    "import json\n",
    "\n",
    "from baselines.common.mpi_fork import mpi_fork\n",
    "from baselines import logger\n",
    "from baselines.logger import Logger\n",
    "from baselines.common.misc_util import (\n",
    "    set_global_seeds,\n",
    "    boolean_flag,\n",
    "    SimpleMonitor\n",
    ")\n",
    "import baselines.ddpg.training as training\n",
    "from baselines.ddpg.models import Actor, Critic\n",
    "from baselines.ddpg.memory import Memory\n",
    "from baselines.ddpg.noise import *\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from mpi4py import MPI\n",
    "\n",
    "\n",
    "from osim.env import *\n",
    "\n",
    "\n",
    "def run(seed, noise_type, num_cpu, layer_norm, logdir, gym_monitor, evaluation, bind_to_core, **kwargs):\n",
    "    kwargs['logdir'] = logdir\n",
    "    whoami = mpi_fork(num_cpu, bind_to_core=bind_to_core)\n",
    "    if whoami == 'parent':\n",
    "        sys.exit(0)\n",
    "\n",
    "    # Configure things.\n",
    "    rank = MPI.COMM_WORLD.Get_rank()\n",
    "    if rank != 0:\n",
    "        # Write to temp directory for all non-master workers.\n",
    "        actual_dir = None\n",
    "        Logger.CURRENT.close()\n",
    "        Logger.CURRENT = Logger(dir=mkdtemp(), output_formats=[])\n",
    "        logger.set_level(logger.DISABLED)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    env = RunEnv(True)\n",
    "    env.reset()\n",
    "       \n",
    "    \n",
    "    # Create envs.\n",
    "    #if rank == 0:\n",
    "    #    env = gym.make(env_id)\n",
    "    #    if gym_monitor and logdir:\n",
    "    #        env = gym.wrappers.Monitor(env, os.path.join(logdir, 'gym_train'), force=True)\n",
    "    #    env = SimpleMonitor(env)\n",
    "\n",
    "    #    if evaluation:\n",
    "    #        eval_env = gym.make(env_id)\n",
    "    #        if gym_monitor and logdir:\n",
    "    #            eval_env = gym.wrappers.Monitor(eval_env, os.path.join(logdir, 'gym_eval'), force=True)\n",
    "    #        eval_env = SimpleMonitor(eval_env)\n",
    "    #    else:\n",
    "    #        eval_env = None\n",
    "    #else:\n",
    "    #    env = gym.make(env_id)\n",
    "    #    if evaluation:\n",
    "    #        eval_env = gym.make(env_id)\n",
    "    #    else:\n",
    "    #        eval_env = None\n",
    "\n",
    "    # Parse noise_type\n",
    "    action_noise = None\n",
    "    param_noise = None\n",
    "    nb_actions = env.action_space.shape[-1]\n",
    "    for current_noise_type in noise_type.split(','):\n",
    "        current_noise_type = current_noise_type.strip()\n",
    "        if current_noise_type == 'none':\n",
    "            pass\n",
    "        elif 'adaptive-param' in current_noise_type:\n",
    "            _, stddev = current_noise_type.split('_')\n",
    "            param_noise = AdaptiveParamNoiseSpec(initial_stddev=float(stddev), desired_action_stddev=float(stddev))\n",
    "        elif 'normal' in current_noise_type:\n",
    "            _, stddev = current_noise_type.split('_')\n",
    "            action_noise = NormalActionNoise(mu=np.zeros(nb_actions), sigma=float(stddev) * np.ones(nb_actions))\n",
    "        elif 'ou' in current_noise_type:\n",
    "            _, stddev = current_noise_type.split('_')\n",
    "            action_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(nb_actions), sigma=float(stddev) * np.ones(nb_actions))\n",
    "        else:\n",
    "            raise RuntimeError('unknown noise type \"{}\"'.format(current_noise_type))\n",
    "\n",
    "    # Configure components.\n",
    "    memory = Memory(limit=int(1e6), action_shape=env.action_space.shape, observation_shape=env.observation_space.shape)\n",
    "    critic = Critic(layer_norm=layer_norm)\n",
    "    actor = Actor(nb_actions, layer_norm=layer_norm)\n",
    "\n",
    "    # Seed everything to make things reproducible.\n",
    "    #seed = seed + 1000000 * rank\n",
    "    #logger.info('rank {}: seed={}, logdir={}'.format(rank, seed, logger.get_dir()))\n",
    "    #tf.reset_default_graph()\n",
    "    #set_global_seeds(seed)\n",
    "    #env.seed(seed)\n",
    "    #if eval_env is not None:\n",
    "    #    eval_env.seed(seed)\n",
    "\n",
    "    # Disable logging for rank != 0 to avoid noise.\n",
    "    if rank == 0:\n",
    "        start_time = time.time()\n",
    "    training.train(env=env, eval_env=None, param_noise=param_noise,\n",
    "        action_noise=action_noise, actor=actor, critic=critic, memory=memory, **kwargs)\n",
    "    env.close()\n",
    "    if eval_env is not None:\n",
    "        eval_env.close()\n",
    "    Logger.CURRENT.close()\n",
    "    if rank == 0:\n",
    "        logger.info('total runtime: {}s'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    \n",
    "    \n",
    "    parser.add_argument('--train', dest='train', action='store_true', default=True)\n",
    "    parser.add_argument('--test', dest='train', action='store_false', default=True)\n",
    "    parser.add_argument('--steps', dest='steps', action='store', default=10000, type=int)\n",
    "    parser.add_argument('--visualize', dest='visualize', action='store_true', default=False)\n",
    "    parser.add_argument('--model', dest='model', action='store', default=\"example.h5f\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #parser.add_argument('--env-id', type=str, default='HalfCheetah-v1')\n",
    "    boolean_flag(parser, 'render-eval', default=False)\n",
    "    boolean_flag(parser, 'layer-norm', default=True)\n",
    "    boolean_flag(parser, 'render', default=False)\n",
    "    parser.add_argument('--num-cpu', type=int, default=1)\n",
    "    boolean_flag(parser, 'normalize-returns', default=False)\n",
    "    boolean_flag(parser, 'normalize-observations', default=True)\n",
    "    parser.add_argument('--seed', type=int, default=0)\n",
    "    parser.add_argument('--critic-l2-reg', type=float, default=1e-2)\n",
    "    parser.add_argument('--batch-size', type=int, default=64)  # per MPI worker\n",
    "    parser.add_argument('--actor-lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--critic-lr', type=float, default=1e-3)\n",
    "    boolean_flag(parser, 'popart', default=False)\n",
    "    parser.add_argument('--gamma', type=float, default=0.99)\n",
    "    parser.add_argument('--reward-scale', type=float, default=1.)\n",
    "    parser.add_argument('--clip-norm', type=float, default=None)\n",
    "    parser.add_argument('--nb-epochs', type=int, default=500)  # with default settings, perform 1M steps total\n",
    "    parser.add_argument('--nb-epoch-cycles', type=int, default=20)\n",
    "    parser.add_argument('--nb-train-steps', type=int, default=50)  # per epoch cycle and MPI worker\n",
    "    parser.add_argument('--nb-eval-steps', type=int, default=100)  # per epoch cycle and MPI worker\n",
    "    parser.add_argument('--nb-rollout-steps', type=int, default=100)  # per epoch cycle and MPI worker\n",
    "    parser.add_argument('--noise-type', type=str, default='adaptive-param_0.2')  # choices are adaptive-param_xx, ou_xx, normal_xx, none\n",
    "    parser.add_argument('--logdir', type=str, default=None)\n",
    "    boolean_flag(parser, 'gym-monitor', default=False)\n",
    "    boolean_flag(parser, 'evaluation', default=True)\n",
    "    boolean_flag(parser, 'bind-to-core', default=False)\n",
    "\n",
    "    return vars(parser.parse_args())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osim.env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.05,\n",
       " 0.0,\n",
       " 0.91,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.06973405523475405,\n",
       " 0.9707656285552124,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.007169537779780744,\n",
       " 1.5365721883823606,\n",
       " 0.0,\n",
       " 0.91,\n",
       " -0.09650084892621281,\n",
       " 0.9964310485677471,\n",
       " 0.007987580127344573,\n",
       " -0.027441466796053905,\n",
       " 0.007987580127344573,\n",
       " -0.027441466796053905,\n",
       " -0.11968333174236659,\n",
       " 0.022952398528571172,\n",
       " -0.11968333174236659,\n",
       " 0.022952398528571172,\n",
       " 1,\n",
       " 1,\n",
       " 100,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = RunEnv(True)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_actions = env.action_space.shape[0]\n",
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(1,) + env.observation_space.shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--train] [--test] [--steps STEPS] [--visualize]\n",
      "                   [--model MODEL] [--render-eval] [--no-render-eval]\n",
      "                   [--layer-norm] [--no-layer-norm] [--render] [--no-render]\n",
      "                   [--num-cpu NUM_CPU] [--normalize-returns]\n",
      "                   [--no-normalize-returns] [--normalize-observations]\n",
      "                   [--no-normalize-observations] [--seed SEED]\n",
      "                   [--critic-l2-reg CRITIC_L2_REG] [--batch-size BATCH_SIZE]\n",
      "                   [--actor-lr ACTOR_LR] [--critic-lr CRITIC_LR] [--popart]\n",
      "                   [--no-popart] [--gamma GAMMA] [--reward-scale REWARD_SCALE]\n",
      "                   [--clip-norm CLIP_NORM] [--nb-epochs NB_EPOCHS]\n",
      "                   [--nb-epoch-cycles NB_EPOCH_CYCLES]\n",
      "                   [--nb-train-steps NB_TRAIN_STEPS]\n",
      "                   [--nb-eval-steps NB_EVAL_STEPS]\n",
      "                   [--nb-rollout-steps NB_ROLLOUT_STEPS]\n",
      "                   [--noise-type NOISE_TYPE] [--logdir LOGDIR] [--gym-monitor]\n",
      "                   [--no-gym-monitor] [--evaluation] [--no-evaluation]\n",
      "                   [--bind-to-core] [--no-bind-to-core]\n",
      "__main__.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-ab51b144-ce07-418f-a8f9-b7fb282e1e3b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/NIPS2017/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "\n",
    "    # Figure out what logdir to use.\n",
    "    if args['logdir'] is None:\n",
    "        args['logdir'] = os.getenv('OPENAI_LOGDIR')\n",
    "    \n",
    "    # Print and save arguments.\n",
    "    logger.info('Arguments:')\n",
    "    for key in sorted(args.keys()):\n",
    "        logger.info('{}: {}'.format(key, args[key]))\n",
    "    logger.info('')\n",
    "    if args['logdir']:\n",
    "        with open(os.path.join(args['logdir'], 'args.json'), 'w') as f:\n",
    "            json.dump(args, f)\n",
    "\n",
    "    # Run actual script.\n",
    "    run(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--train] [--test] [--steps STEPS] [--visualize]\n",
      "                   [--model MODEL] [--render-eval] [--no-render-eval]\n",
      "                   [--layer-norm] [--no-layer-norm] [--render] [--no-render]\n",
      "                   [--num-cpu NUM_CPU] [--normalize-returns]\n",
      "                   [--no-normalize-returns] [--normalize-observations]\n",
      "                   [--no-normalize-observations] [--seed SEED]\n",
      "                   [--critic-l2-reg CRITIC_L2_REG] [--batch-size BATCH_SIZE]\n",
      "                   [--actor-lr ACTOR_LR] [--critic-lr CRITIC_LR] [--popart]\n",
      "                   [--no-popart] [--gamma GAMMA] [--reward-scale REWARD_SCALE]\n",
      "                   [--clip-norm CLIP_NORM] [--nb-epochs NB_EPOCHS]\n",
      "                   [--nb-epoch-cycles NB_EPOCH_CYCLES]\n",
      "                   [--nb-train-steps NB_TRAIN_STEPS]\n",
      "                   [--nb-eval-steps NB_EVAL_STEPS]\n",
      "                   [--nb-rollout-steps NB_ROLLOUT_STEPS]\n",
      "                   [--noise-type NOISE_TYPE] [--logdir LOGDIR] [--gym-monitor]\n",
      "                   [--no-gym-monitor] [--evaluation] [--no-evaluation]\n",
      "                   [--bind-to-core] [--no-bind-to-core]\n",
      "__main__.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-ab51b144-ce07-418f-a8f9-b7fb282e1e3b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/NIPS2017/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "    args = parse_args()\n",
    "\n",
    "    # Figure out what logdir to use.\n",
    "    if args['logdir'] is None:\n",
    "        args['logdir'] = os.getenv('OPENAI_LOGDIR')\n",
    "    \n",
    "    # Print and save arguments.\n",
    "    logger.info('Arguments:')\n",
    "    for key in sorted(args.keys()):\n",
    "        logger.info('{}: {}'.format(key, args[key]))\n",
    "    logger.info('')\n",
    "    if args['logdir']:\n",
    "        with open(os.path.join(args['logdir'], 'args.json'), 'w') as f:\n",
    "            json.dump(args, f)\n",
    "\n",
    "    # Run actual script.\n",
    "    run(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NIPS2017]",
   "language": "python",
   "name": "conda-env-NIPS2017-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
